{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import gymnasium as gym\n",
    "from torch.optim import Adam\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from rlib.algorithms.a2c import a2c\n",
    "from rlib.algorithms.ppo import ppo\n",
    "from rlib.algorithms.reinforce import reinforce\n",
    "from rlib.common.evaluation import get_trajectory, validation\n",
    "from rlib.common.policies import (\n",
    "    DiscreteStochasticMlpPolicy,\n",
    "    MlpCritic,\n",
    "    StochasticMlpPolicy,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.3602141e+00  2.9011312e+38 -3.8685688e-01 -2.1509378e+38] (4,)\n",
      "0 ()\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.sample(), env.observation_space.sample().shape)\n",
    "print(env.action_space.sample(), env.action_space.sample().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9877751  0.8809305 -3.9422476] (3,)\n",
      "[1.2642736] (1,)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.sample(), env.observation_space.sample().shape)\n",
    "print(env.action_space.sample(), env.action_space.sample().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.1782722  -0.7862177  -0.21187767  1.7170434  -0.36368287 -1.8191515\n",
      " -1.2151375  -2.8275526   0.22590871  0.26896387 -4.490998    1.5079538\n",
      " -0.77005315  3.3377466   0.5328349  -0.03321891 -0.29422292 -0.63958776\n",
      " -0.51001704 -0.30934176 -0.8103885   0.98810804  0.23579766  0.16712207] (24,)\n",
      "[ 0.30528358 -0.8524173   0.8779433   0.30583316] (4,)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.sample(), env.observation_space.sample().shape)\n",
    "print(env.action_space.sample(), env.action_space.sample().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    }
   ],
   "source": [
    "discrete = False\n",
    "\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "if discrete:\n",
    "    action_dim = env.action_space.n\n",
    "else:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "\n",
    "print(obs_dim, action_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = DiscreteStochasticMlpPolicy(input_size, output_size)\n",
    "policy = StochasticMlpPolicy(input_size, output_size, action_scale=2)\n",
    "optimizer = Adam(policy.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = get_trajectory(env, policy, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce(env, policy, optimizer, total_timesteps=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1113, grad_fn=<UnbindBackward0>),\n",
       " tensor(-0.9518, grad_fn=<UnbindBackward0>))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.forward(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1697.8311858462926"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(env, policy, deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor = DiscreteStochasticMlpPolicy(input_size, output_size)\n",
    "actor = StochasticMlpPolicy(input_size, output_size, action_scale=2)\n",
    "critic = MlpCritic(input_size)\n",
    "\n",
    "actor_optimizer = Adam(actor.parameters(), lr=3e-4)\n",
    "critic_optimizer = Adam(critic.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_n: 2000\n",
      "mean_trajectory_rewards: -1217.060302734375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 4000\n",
      "mean_trajectory_rewards: -1151.2532958984375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 6000\n",
      "mean_trajectory_rewards: -1255.719482421875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 8000\n",
      "mean_trajectory_rewards: -991.3551025390625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 10000\n",
      "mean_trajectory_rewards: -1137.3951416015625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 12000\n",
      "mean_trajectory_rewards: -1250.375244140625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 14000\n",
      "mean_trajectory_rewards: -1279.54296875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 16000\n",
      "mean_trajectory_rewards: -1271.0977783203125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 18000\n",
      "mean_trajectory_rewards: -1371.1456298828125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 20000\n",
      "mean_trajectory_rewards: -1120.009033203125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 22000\n",
      "mean_trajectory_rewards: -1090.566162109375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 24000\n",
      "mean_trajectory_rewards: -1227.2841796875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 26000\n",
      "mean_trajectory_rewards: -1220.4176025390625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 28000\n",
      "mean_trajectory_rewards: -1245.642578125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 30000\n",
      "mean_trajectory_rewards: -1290.2310791015625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 32000\n",
      "mean_trajectory_rewards: -1316.8909912109375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 34000\n",
      "mean_trajectory_rewards: -1198.275390625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 36000\n",
      "mean_trajectory_rewards: -1322.880126953125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 38000\n",
      "mean_trajectory_rewards: -1325.662353515625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 40000\n",
      "mean_trajectory_rewards: -1188.651123046875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 42000\n",
      "mean_trajectory_rewards: -1265.839599609375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 44000\n",
      "mean_trajectory_rewards: -1293.421875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 46000\n",
      "mean_trajectory_rewards: -1266.294921875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 48000\n",
      "mean_trajectory_rewards: -1237.419677734375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 50000\n",
      "mean_trajectory_rewards: -1295.2279052734375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 52000\n",
      "mean_trajectory_rewards: -1231.1156005859375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 54000\n",
      "mean_trajectory_rewards: -1277.49658203125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 56000\n",
      "mean_trajectory_rewards: -1255.4990234375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 58000\n",
      "mean_trajectory_rewards: -1237.3846435546875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 60000\n",
      "mean_trajectory_rewards: -1349.526123046875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 62000\n",
      "mean_trajectory_rewards: -1225.7425537109375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 64000\n",
      "mean_trajectory_rewards: -1177.554931640625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 66000\n",
      "mean_trajectory_rewards: -1345.055908203125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 68000\n",
      "mean_trajectory_rewards: -1227.5626220703125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 70000\n",
      "mean_trajectory_rewards: -1211.6392822265625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 72000\n",
      "mean_trajectory_rewards: -1210.746337890625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 74000\n",
      "mean_trajectory_rewards: -1285.099853515625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 76000\n",
      "mean_trajectory_rewards: -1319.9727783203125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 78000\n",
      "mean_trajectory_rewards: -1113.958984375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 80000\n",
      "mean_trajectory_rewards: -1191.1107177734375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 82000\n",
      "mean_trajectory_rewards: -1272.0518798828125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 84000\n",
      "mean_trajectory_rewards: -1036.675537109375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 86000\n",
      "mean_trajectory_rewards: -1179.3885498046875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 88000\n",
      "mean_trajectory_rewards: -1284.9451904296875\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 90000\n",
      "mean_trajectory_rewards: -1301.1676025390625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 92000\n",
      "mean_trajectory_rewards: -1188.765869140625\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 94000\n",
      "mean_trajectory_rewards: -1278.2042236328125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 96000\n",
      "mean_trajectory_rewards: -1130.3740234375\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 98000\n",
      "mean_trajectory_rewards: -1186.491455078125\n",
      "mean_trajectory_length: 199.90000915527344\n",
      "steps_n: 100000\n",
      "mean_trajectory_rewards: -1358.4803466796875\n",
      "mean_trajectory_length: 199.90000915527344\n"
     ]
    }
   ],
   "source": [
    "a2c(env, actor, critic, actor_optimizer, critic_optimizer, total_timesteps=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1205.740195305502"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(env, actor, deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "if discrete:\n",
    "    actor = DiscreteStochasticMlpPolicy(obs_dim, action_dim)\n",
    "else:\n",
    "    actor = StochasticMlpPolicy(obs_dim, action_dim)\n",
    "\n",
    "critic = MlpCritic(obs_dim)\n",
    "\n",
    "actor_optimizer = Adam(actor.parameters(), lr=1e-4)\n",
    "critic_optimizer = Adam(critic.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_n: 4000\n",
      "mean_trajectory_rewards: -1381.993408203125\n",
      "mean_trajectory_length: 199.9499969482422\n",
      "steps_n: 8000\n",
      "mean_trajectory_rewards: -1453.8677978515625\n",
      "mean_trajectory_length: 199.9499969482422\n",
      "steps_n: 12000\n",
      "mean_trajectory_rewards: -1234.894287109375\n",
      "mean_trajectory_length: 199.9499969482422\n",
      "steps_n: 16000\n",
      "mean_trajectory_rewards: -1294.49365234375\n",
      "mean_trajectory_length: 199.9499969482422\n",
      "steps_n: 20000\n",
      "mean_trajectory_rewards: -1193.3192138671875\n",
      "mean_trajectory_length: 199.9499969482422\n",
      "steps_n: 24000\n",
      "mean_trajectory_rewards: -1218.862548828125\n",
      "mean_trajectory_length: 199.9499969482422\n",
      "steps_n: 28000\n",
      "mean_trajectory_rewards: -1150.4578857421875\n",
      "mean_trajectory_length: 199.9499969482422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[462], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mppo\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic_optimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\никита\\coding\\rl\\rlib\\rlib\\algorithms\\ppo.py:51\u001b[0m, in \u001b[0;36mppo\u001b[1;34m(env, actor, critic, actor_optimizer, critic_optimizer, total_timesteps, trajectories_n, epoch_n, batch_size)\u001b[0m\n\u001b[0;32m     48\u001b[0m actor_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     49\u001b[0m actor_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 51\u001b[0m \u001b[43mloss\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcritic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m critic_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     53\u001b[0m critic_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\никита\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:491\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    483\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    484\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[1;32m--> 491\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\никита\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo(env, actor, critic, actor_optimizer, critic_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-196.01602833050853"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(env, actor, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'states': [array([ 0.01916282,  0.99981636, -0.15358567], dtype=float32),\n",
       "  array([0.00435015, 0.9999905 , 0.2962766 ], dtype=float32),\n",
       "  array([-0.03295734,  0.99945676,  0.7462695 ], dtype=float32),\n",
       "  array([-0.09470269,  0.9955056 ,  1.2376302 ], dtype=float32),\n",
       "  array([-0.17810252,  0.98401195,  1.6842595 ], dtype=float32),\n",
       "  array([-0.28293487,  0.9591391 ,  2.155897  ], dtype=float32),\n",
       "  array([-0.4048079 ,  0.91440177,  2.598322  ], dtype=float32),\n",
       "  array([-0.54566306,  0.83800465,  3.2082286 ], dtype=float32),\n",
       "  array([-0.7002716,  0.7138765,  3.9719546], dtype=float32),\n",
       "  array([-0.8438213,  0.5366243,  4.5717387], dtype=float32),\n",
       "  array([-0.950611 ,  0.3103848,  5.0166736], dtype=float32),\n",
       "  array([-0.9989602 ,  0.04559056,  5.399829  ], dtype=float32),\n",
       "  array([-0.9723702 , -0.23344412,  5.624491  ], dtype=float32),\n",
       "  array([-0.8674159, -0.4975838,  5.703857 ], dtype=float32),\n",
       "  array([-0.6964751, -0.717581 ,  5.5902367], dtype=float32),\n",
       "  array([-0.481943 , -0.8762026,  5.352051 ], dtype=float32),\n",
       "  array([-0.25444052, -0.9670884 ,  4.912036  ], dtype=float32),\n",
       "  array([-0.03292721, -0.9994578 ,  4.4867196 ], dtype=float32),\n",
       "  array([ 0.1664823 , -0.98604447,  4.0038853 ], dtype=float32),\n",
       "  array([ 0.33864713, -0.94091344,  3.5643518 ], dtype=float32),\n",
       "  array([ 0.47991657, -0.87731415,  3.1016183 ], dtype=float32),\n",
       "  array([ 0.59405124, -0.8044272 ,  2.7105222 ], dtype=float32),\n",
       "  array([ 0.67936665, -0.733799  ,  2.216269  ], dtype=float32),\n",
       "  array([ 0.74810064, -0.6635853 ,  1.9659197 ], dtype=float32),\n",
       "  array([ 0.7984134, -0.6021097,  1.5892067], dtype=float32),\n",
       "  array([ 0.83637565, -0.5481567 ,  1.3196421 ], dtype=float32),\n",
       "  array([ 0.8628513, -0.5054579,  1.0049242], dtype=float32),\n",
       "  array([ 0.8810146 , -0.4730891 ,  0.74237436], dtype=float32),\n",
       "  array([ 0.8937062 , -0.44865268,  0.55073184], dtype=float32),\n",
       "  array([ 0.9049453 , -0.42552784,  0.5142423 ], dtype=float32),\n",
       "  array([ 0.9147384 , -0.40404662,  0.47217458], dtype=float32),\n",
       "  array([ 0.9232306 , -0.38424644,  0.43089792], dtype=float32),\n",
       "  array([ 0.92981184, -0.36803526,  0.34992772], dtype=float32),\n",
       "  array([ 0.93463427, -0.35561046,  0.26655877], dtype=float32),\n",
       "  array([ 0.93663913, -0.35029584,  0.11360425], dtype=float32),\n",
       "  array([ 0.93883824, -0.3443584 ,  0.1266322 ], dtype=float32),\n",
       "  array([ 0.94170386, -0.336443  ,  0.16836339], dtype=float32),\n",
       "  array([ 0.9446489 , -0.32808286,  0.17727505], dtype=float32),\n",
       "  array([ 0.9463561 , -0.32312542,  0.10486339], dtype=float32),\n",
       "  array([ 0.9481169 , -0.31792197,  0.1098658 ], dtype=float32),\n",
       "  array([ 0.946953  , -0.32137206, -0.07282221], dtype=float32),\n",
       "  array([ 0.94405204, -0.32979658, -0.17820123], dtype=float32),\n",
       "  array([ 0.94196314, -0.33571628, -0.12554868], dtype=float32),\n",
       "  array([ 0.9405612 , -0.3396243 , -0.08303715], dtype=float32),\n",
       "  array([ 0.9396439 , -0.34215388, -0.0538155 ], dtype=float32),\n",
       "  array([ 0.9392239 , -0.34330523, -0.02451155], dtype=float32),\n",
       "  array([ 0.93953264, -0.34245935,  0.01800952], dtype=float32),\n",
       "  array([ 0.9405756 , -0.3395844 ,  0.06116502], dtype=float32),\n",
       "  array([ 0.9410875 , -0.33816326,  0.03021092], dtype=float32),\n",
       "  array([ 0.9414409 , -0.33717808,  0.02093311], dtype=float32),\n",
       "  array([ 0.9406825 , -0.3392882 , -0.04484566], dtype=float32),\n",
       "  array([ 0.93966454, -0.34209725, -0.05975619], dtype=float32),\n",
       "  array([ 0.93812364, -0.34630042, -0.0895341 ], dtype=float32),\n",
       "  array([ 0.9372679 , -0.34860992, -0.04925941], dtype=float32),\n",
       "  array([ 0.937081  , -0.34911212, -0.01071686], dtype=float32),\n",
       "  array([ 0.93698806, -0.34936142, -0.00532131], dtype=float32),\n",
       "  array([ 0.9356138 , -0.35302514, -0.0782593 ], dtype=float32),\n",
       "  array([ 0.9348522 , -0.3550372 , -0.04302816], dtype=float32),\n",
       "  array([ 0.93468684, -0.35547218, -0.00930607], dtype=float32),\n",
       "  array([ 0.9342961 , -0.356498  , -0.02195496], dtype=float32),\n",
       "  array([ 0.93448615, -0.35599944,  0.01067154], dtype=float32),\n",
       "  array([ 0.9352613 , -0.35395804,  0.04367197], dtype=float32),\n",
       "  array([ 0.9366382 , -0.35029832,  0.07820343], dtype=float32),\n",
       "  array([ 0.9386452 , -0.34488437,  0.1154797 ], dtype=float32),\n",
       "  array([ 0.9413205 , -0.3375141 ,  0.15681642], dtype=float32),\n",
       "  array([ 0.94281226, -0.33332428,  0.08894904], dtype=float32),\n",
       "  array([ 0.94480735, -0.32762644,  0.12074116], dtype=float32),\n",
       "  array([ 0.94755876, -0.31958166,  0.17004597], dtype=float32),\n",
       "  array([ 0.95117676, -0.30864674,  0.23035973], dtype=float32),\n",
       "  array([ 0.954076  , -0.29956475,  0.1906713 ], dtype=float32),\n",
       "  array([ 0.9572048 , -0.28941134,  0.2124924 ], dtype=float32),\n",
       "  array([ 0.9597621 , -0.28081447,  0.17938331], dtype=float32),\n",
       "  array([ 0.96252894, -0.27117893,  0.20049985], dtype=float32),\n",
       "  array([ 0.9643269 , -0.26471412,  0.13420333], dtype=float32),\n",
       "  array([ 0.9670981 , -0.2544037 ,  0.21352759], dtype=float32),\n",
       "  array([ 0.9698651, -0.2436427,  0.2222221], dtype=float32),\n",
       "  array([ 0.9714837 , -0.23710641,  0.13467479], dtype=float32),\n",
       "  array([ 0.9726018 , -0.2324774 ,  0.09524292], dtype=float32),\n",
       "  array([ 0.9728206 , -0.23156007,  0.01886121], dtype=float32),\n",
       "  array([ 0.9742806 , -0.22533812,  0.12781937], dtype=float32),\n",
       "  array([ 0.97603005, -0.21763591,  0.15796803], dtype=float32),\n",
       "  array([ 0.9791312, -0.203229 ,  0.2947411], dtype=float32),\n",
       "  array([ 0.9815049, -0.1914368,  0.2405762], dtype=float32),\n",
       "  array([ 0.98371077, -0.1797587 ,  0.23769322], dtype=float32),\n",
       "  array([ 0.9863167 , -0.16486162,  0.30246854], dtype=float32),\n",
       "  array([ 0.98845   , -0.15154743,  0.26968235], dtype=float32),\n",
       "  array([ 0.99044   , -0.13794428,  0.27496082], dtype=float32),\n",
       "  array([ 0.9914338 , -0.13060999,  0.1480268 ], dtype=float32),\n",
       "  array([ 0.9920569 , -0.12578967,  0.09720849], dtype=float32),\n",
       "  array([ 0.9926442 , -0.12106814,  0.0951585 ], dtype=float32),\n",
       "  array([ 0.9934443 , -0.11431697,  0.13596864], dtype=float32),\n",
       "  array([ 0.9942041, -0.1075091,  0.137003 ], dtype=float32),\n",
       "  array([ 0.9952382 , -0.09747294,  0.20178661], dtype=float32),\n",
       "  array([ 0.9958877 , -0.09059614,  0.1381485 ], dtype=float32),\n",
       "  array([ 0.9963366 , -0.08551846,  0.10194981], dtype=float32),\n",
       "  array([ 0.99698454, -0.0776006 ,  0.15888683], dtype=float32),\n",
       "  array([ 0.99735   , -0.07275318,  0.09722365], dtype=float32),\n",
       "  array([ 0.9982211 , -0.05962106,  0.26322153], dtype=float32),\n",
       "  array([ 0.998587  , -0.05314117,  0.1298044 ], dtype=float32),\n",
       "  array([ 0.9991741 , -0.04063378,  0.25042504], dtype=float32),\n",
       "  array([ 0.9995243 , -0.03084115,  0.1959784 ], dtype=float32),\n",
       "  array([ 0.9997805 , -0.02095341,  0.197822  ], dtype=float32),\n",
       "  array([ 0.9999833 , -0.00578032,  0.3034918 ], dtype=float32),\n",
       "  array([0.9999955 , 0.00299533, 0.17551386], dtype=float32),\n",
       "  array([0.99990654, 0.01366968, 0.21349525], dtype=float32),\n",
       "  array([0.99973935, 0.02283138, 0.1832652 ], dtype=float32),\n",
       "  array([0.9993666 , 0.03558627, 0.2552084 ], dtype=float32),\n",
       "  array([0.9989094 , 0.04669047, 0.22227342], dtype=float32),\n",
       "  array([0.99863505, 0.05223045, 0.11093547], dtype=float32),\n",
       "  array([0.9982064 , 0.05986655, 0.15296277], dtype=float32),\n",
       "  array([0.99769664, 0.06783361, 0.15966749], dtype=float32),\n",
       "  array([0.9975068 , 0.07057083, 0.05487584], dtype=float32),\n",
       "  array([0.9974494 , 0.07137749, 0.01617411], dtype=float32),\n",
       "  array([ 0.99790496,  0.06469685, -0.1339234 ], dtype=float32),\n",
       "  array([ 0.9982718 ,  0.0587654 , -0.11885584], dtype=float32),\n",
       "  array([ 0.99853283,  0.05414981, -0.09245928], dtype=float32),\n",
       "  array([ 0.9989306 ,  0.04623517, -0.15849297], dtype=float32),\n",
       "  array([ 0.99918675,  0.04032087, -0.11839716], dtype=float32),\n",
       "  array([ 0.9994378 ,  0.03352622, -0.13598602], dtype=float32),\n",
       "  array([ 0.9998144 ,  0.01926745, -0.28527716], dtype=float32),\n",
       "  array([ 0.9999951 ,  0.00312613, -0.3228502 ], dtype=float32),\n",
       "  array([ 0.99999475, -0.00323609, -0.1272446 ], dtype=float32),\n",
       "  array([ 0.999983  , -0.00583284, -0.05193557], dtype=float32),\n",
       "  array([ 0.99995357, -0.0096391 , -0.07612759], dtype=float32),\n",
       "  array([ 0.99982804, -0.01854468, -0.1781299 ], dtype=float32),\n",
       "  array([ 0.999615  , -0.02774648, -0.18408586], dtype=float32),\n",
       "  array([ 0.9992498 , -0.0387275 , -0.21974294], dtype=float32),\n",
       "  array([ 0.9989667 , -0.04544789, -0.1345273 ], dtype=float32),\n",
       "  array([ 0.99876875, -0.0496081 , -0.08329843], dtype=float32),\n",
       "  array([ 0.9984178 , -0.05623072, -0.1326384 ], dtype=float32),\n",
       "  array([ 0.99760973, -0.06909963, -0.25788686], dtype=float32),\n",
       "  array([ 0.9965906 , -0.08250523, -0.26888773], dtype=float32),\n",
       "  array([ 0.9952889 , -0.09695327, -0.29013366], dtype=float32),\n",
       "  array([ 0.9947575 , -0.10226228, -0.10671109], dtype=float32),\n",
       "  array([ 0.99376225, -0.11151926, -0.1862072 ], dtype=float32),\n",
       "  array([ 0.9917823 , -0.12793699, -0.33073744], dtype=float32),\n",
       "  array([ 0.99087006, -0.13482024, -0.13886917], dtype=float32),\n",
       "  array([ 0.99058765, -0.13688008, -0.04158227], dtype=float32),\n",
       "  array([ 0.99089706, -0.13462184,  0.04558679], dtype=float32),\n",
       "  array([ 0.99182504, -0.1276052 ,  0.14155504], dtype=float32),\n",
       "  array([ 0.99238104, -0.1232067 ,  0.08867034], dtype=float32),\n",
       "  array([ 0.99195087, -0.1266234 , -0.06887385], dtype=float32),\n",
       "  array([ 0.992474  , -0.12245521,  0.0840182 ], dtype=float32),\n",
       "  array([ 0.9923823 , -0.12319679, -0.01494474], dtype=float32),\n",
       "  array([ 0.9927156 , -0.12048135,  0.05471643], dtype=float32),\n",
       "  array([ 0.9927943 , -0.11983144,  0.01309316], dtype=float32),\n",
       "  array([ 0.99331176, -0.1154632 ,  0.08797563], dtype=float32),\n",
       "  array([ 0.99347156, -0.11408003,  0.02784758], dtype=float32),\n",
       "  array([ 0.99354196, -0.11346543,  0.0123724 ], dtype=float32),\n",
       "  array([ 0.99408615, -0.10859411,  0.09803254], dtype=float32),\n",
       "  array([ 0.9945823 , -0.103952  ,  0.09337108], dtype=float32),\n",
       "  array([ 0.9943113 , -0.10651342, -0.05151439], dtype=float32),\n",
       "  array([ 0.99385124, -0.11072347, -0.08470231], dtype=float32),\n",
       "  array([ 0.99268925, -0.1206982 , -0.20084457], dtype=float32),\n",
       "  array([ 0.99193615, -0.12673855, -0.12174258], dtype=float32),\n",
       "  array([ 0.9917462 , -0.12821656, -0.02980345], dtype=float32),\n",
       "  array([ 0.9915895 , -0.12942283, -0.02432778], dtype=float32),\n",
       "  array([ 0.99195224, -0.12661272,  0.05666818], dtype=float32),\n",
       "  array([ 0.9924669 , -0.12251262,  0.08264602], dtype=float32),\n",
       "  array([ 0.9934856 , -0.11395732,  0.172315  ], dtype=float32),\n",
       "  array([ 0.9942079 , -0.10747372,  0.13047439], dtype=float32),\n",
       "  array([ 0.99525785, -0.09727184,  0.20511621], dtype=float32),\n",
       "  array([ 0.9957806 , -0.09176594,  0.11061346], dtype=float32),\n",
       "  array([ 0.99549544, -0.09480955, -0.06113882], dtype=float32),\n",
       "  array([ 0.99504495, -0.09942642, -0.09277602], dtype=float32),\n",
       "  array([ 0.99500924, -0.09978309, -0.00716896], dtype=float32),\n",
       "  array([ 0.9946781 , -0.10303181, -0.06531118], dtype=float32),\n",
       "  array([ 0.9941465 , -0.10804047, -0.10073608], dtype=float32),\n",
       "  array([ 0.9940726 , -0.10871813, -0.01363342], dtype=float32),\n",
       "  array([ 0.9947822, -0.1020216,  0.1346805], dtype=float32),\n",
       "  array([ 0.9948286 , -0.10156837,  0.00911205], dtype=float32),\n",
       "  array([ 0.99482244, -0.10162827, -0.00120411], dtype=float32),\n",
       "  array([ 0.994458  , -0.10513467, -0.07050577], dtype=float32),\n",
       "  array([ 0.9940466 , -0.10895553, -0.07685899], dtype=float32),\n",
       "  array([ 0.9930862 , -0.11738705, -0.16972126], dtype=float32),\n",
       "  array([ 0.99220306, -0.12463183, -0.14596872], dtype=float32),\n",
       "  array([ 0.99179035, -0.12787464, -0.06537939], dtype=float32),\n",
       "  array([ 0.9910781 , -0.13328247, -0.10909076], dtype=float32),\n",
       "  array([ 0.99133205, -0.13138007,  0.03838573], dtype=float32),\n",
       "  array([ 0.99160194, -0.12932721,  0.04141032], dtype=float32),\n",
       "  array([ 0.99172264, -0.12839848,  0.01873097], dtype=float32),\n",
       "  array([ 0.99150205, -0.1300913 , -0.03414286], dtype=float32),\n",
       "  array([ 0.9914455 , -0.13052127, -0.00867324], dtype=float32),\n",
       "  array([ 0.9912453 , -0.13203302, -0.03049904], dtype=float32),\n",
       "  array([ 0.99134433, -0.13128763,  0.0150387 ], dtype=float32),\n",
       "  array([ 0.9917782 , -0.12796894,  0.06693877], dtype=float32),\n",
       "  array([ 0.99223214, -0.12439997,  0.07195444], dtype=float32),\n",
       "  array([ 0.9935015 , -0.11381929,  0.213132  ], dtype=float32),\n",
       "  array([ 0.99468195, -0.10299444,  0.21778145], dtype=float32),\n",
       "  array([ 0.9957779 , -0.09179497,  0.22506064], dtype=float32),\n",
       "  array([ 0.99649674, -0.0836314 ,  0.16390358], dtype=float32),\n",
       "  array([ 0.99712294, -0.07580141,  0.15710022], dtype=float32),\n",
       "  array([ 0.9974154 , -0.07185076,  0.0792292 ], dtype=float32),\n",
       "  array([ 0.9972213 , -0.0744966 , -0.05305909], dtype=float32),\n",
       "  array([ 0.9973739 , -0.07242512,  0.04154187], dtype=float32),\n",
       "  array([ 0.9972464 , -0.07415936, -0.03477837], dtype=float32),\n",
       "  array([ 0.9975221 , -0.07035384,  0.07631   ], dtype=float32),\n",
       "  array([ 0.99757564, -0.06959046,  0.01530518], dtype=float32),\n",
       "  array([ 0.9977919 , -0.06641828,  0.06359066], dtype=float32),\n",
       "  array([ 0.998423  , -0.05613846,  0.20598459], dtype=float32)],\n",
       " 'actions': [array([-3.1931024], dtype=float32),\n",
       "  array([-3.5744524], dtype=float32),\n",
       "  array([-1.7215452], dtype=float32),\n",
       "  array([-2.7664814], dtype=float32),\n",
       "  array([-1.7758106], dtype=float32),\n",
       "  array([-1.8461949], dtype=float32),\n",
       "  array([-0.505965], dtype=float32),\n",
       "  array([0.90148306], dtype=float32),\n",
       "  array([0.42917776], dtype=float32),\n",
       "  array([0.283113], dtype=float32),\n",
       "  array([1.002445], dtype=float32),\n",
       "  array([1.2697933], dtype=float32),\n",
       "  array([1.6963267], dtype=float32),\n",
       "  array([1.7304512], dtype=float32),\n",
       "  array([2.0547645], dtype=float32),\n",
       "  array([1.4475776], dtype=float32),\n",
       "  array([2.034721], dtype=float32),\n",
       "  array([1.7783941], dtype=float32),\n",
       "  array([2.0426695], dtype=float32),\n",
       "  array([1.6196772], dtype=float32),\n",
       "  array([1.7792628], dtype=float32),\n",
       "  array([0.7271151], dtype=float32),\n",
       "  array([2.1233225], dtype=float32),\n",
       "  array([0.80650586], dtype=float32),\n",
       "  array([1.2134511], dtype=float32),\n",
       "  array([0.6426643], dtype=float32),\n",
       "  array([0.77695686], dtype=float32),\n",
       "  array([1.0878286], dtype=float32),\n",
       "  array([2.5268688], dtype=float32),\n",
       "  array([1.8471878], dtype=float32),\n",
       "  array([1.7450554], dtype=float32),\n",
       "  array([1.3814309], dtype=float32),\n",
       "  array([1.2843832], dtype=float32),\n",
       "  array([0.7583555], dtype=float32),\n",
       "  array([1.8383322], dtype=float32),\n",
       "  array([2.2506664], dtype=float32),\n",
       "  array([1.741626], dtype=float32),\n",
       "  array([1.15767], dtype=float32),\n",
       "  array([1.6489766], dtype=float32),\n",
       "  array([0.3716898], dtype=float32),\n",
       "  array([0.9043335], dtype=float32),\n",
       "  array([2.983618], dtype=float32),\n",
       "  array([1.9619915], dtype=float32),\n",
       "  array([1.8929324], dtype=float32),\n",
       "  array([1.906129], dtype=float32),\n",
       "  array([2.549171], dtype=float32),\n",
       "  array([2.1950612], dtype=float32),\n",
       "  array([1.4915614], dtype=float32),\n",
       "  array([1.6289642], dtype=float32),\n",
       "  array([1.2473652], dtype=float32),\n",
       "  array([1.5970374], dtype=float32),\n",
       "  array([1.511967], dtype=float32),\n",
       "  array([2.714793], dtype=float32),\n",
       "  array([2.0678933], dtype=float32),\n",
       "  array([1.7815309], dtype=float32),\n",
       "  array([1.2605538], dtype=float32),\n",
       "  array([2.7851796], dtype=float32),\n",
       "  array([2.038232], dtype=float32),\n",
       "  array([1.6930349], dtype=float32),\n",
       "  array([2.7248101], dtype=float32),\n",
       "  array([2.200043], dtype=float32),\n",
       "  array([2.7662444], dtype=float32),\n",
       "  array([2.5577123], dtype=float32),\n",
       "  array([2.305554], dtype=float32),\n",
       "  array([1.2351213], dtype=float32),\n",
       "  array([1.8785689], dtype=float32),\n",
       "  array([1.966831], dtype=float32),\n",
       "  array([2.833227], dtype=float32),\n",
       "  array([1.2786441], dtype=float32),\n",
       "  array([1.6432978], dtype=float32),\n",
       "  array([1.2263293], dtype=float32),\n",
       "  array([1.5448494], dtype=float32),\n",
       "  array([0.9139177], dtype=float32),\n",
       "  array([1.8523991], dtype=float32),\n",
       "  array([1.329982], dtype=float32),\n",
       "  array([0.63456476], dtype=float32),\n",
       "  array([0.922653], dtype=float32),\n",
       "  array([0.65317553], dtype=float32),\n",
       "  array([1.8841882], dtype=float32),\n",
       "  array([1.3276815], dtype=float32),\n",
       "  array([2.078362], dtype=float32),\n",
       "  array([0.6550456], dtype=float32),\n",
       "  array([0.9379642], dtype=float32),\n",
       "  array([1.3306289], dtype=float32),\n",
       "  array([0.6057335], dtype=float32),\n",
       "  array([0.79292697], dtype=float32),\n",
       "  array([-0.1565054], dtype=float32),\n",
       "  array([0.31426123], dtype=float32),\n",
       "  array([0.61528176], dtype=float32),\n",
       "  array([0.8774084], dtype=float32),\n",
       "  array([0.5784806], dtype=float32),\n",
       "  array([0.96943617], dtype=float32),\n",
       "  array([0.06311069], dtype=float32),\n",
       "  array([0.21165605], dtype=float32),\n",
       "  array([0.8071725], dtype=float32),\n",
       "  array([-0.02308492], dtype=float32),\n",
       "  array([1.4704183], dtype=float32),\n",
       "  array([-0.59134215], dtype=float32),\n",
       "  array([1.0698434], dtype=float32),\n",
       "  array([-0.1598087], dtype=float32),\n",
       "  array([0.16649644], dtype=float32),\n",
       "  array([0.8092325], dtype=float32),\n",
       "  array([-0.8242847], dtype=float32),\n",
       "  array([0.23823258], dtype=float32),\n",
       "  array([-0.26988214], dtype=float32),\n",
       "  array([0.3654646], dtype=float32),\n",
       "  array([-0.39749792], dtype=float32),\n",
       "  array([-0.9757054], dtype=float32),\n",
       "  array([0.0190298], dtype=float32),\n",
       "  array([-0.25463462], dtype=float32),\n",
       "  array([-1.0377791], dtype=float32),\n",
       "  array([-0.61086565], dtype=float32),\n",
       "  array([-1.3575375], dtype=float32),\n",
       "  array([-0.22303382], dtype=float32),\n",
       "  array([-0.11784993], dtype=float32),\n",
       "  array([-0.7109736], dtype=float32),\n",
       "  array([0.03612946], dtype=float32),\n",
       "  array([-0.31886333], dtype=float32),\n",
       "  array([-1.1629053], dtype=float32),\n",
       "  array([-0.3468242], dtype=float32),\n",
       "  array([1.2884065], dtype=float32),\n",
       "  array([0.51824075], dtype=float32),\n",
       "  array([-0.13211596], dtype=float32),\n",
       "  array([-0.63181984], dtype=float32),\n",
       "  array([0.05301693], dtype=float32),\n",
       "  array([-0.09898147], dtype=float32),\n",
       "  array([0.7617418], dtype=float32),\n",
       "  array([0.5687652], dtype=float32),\n",
       "  array([-0.08089259], dtype=float32),\n",
       "  array([-0.55383605], dtype=float32),\n",
       "  array([0.27215898], dtype=float32),\n",
       "  array([0.2708866], dtype=float32),\n",
       "  array([1.7075834], dtype=float32),\n",
       "  array([-0.01866269], dtype=float32),\n",
       "  array([-0.40593863], dtype=float32),\n",
       "  array([1.9188068], dtype=float32),\n",
       "  array([1.3226805], dtype=float32),\n",
       "  array([1.2655275], dtype=float32),\n",
       "  array([1.3128976], dtype=float32),\n",
       "  array([0.2854613], dtype=float32),\n",
       "  array([-0.43426108], dtype=float32),\n",
       "  array([1.6523974], dtype=float32),\n",
       "  array([-0.04747689], dtype=float32),\n",
       "  array([1.0803918], dtype=float32),\n",
       "  array([0.3249183], dtype=float32),\n",
       "  array([1.0983737], dtype=float32),\n",
       "  array([0.17646235], dtype=float32),\n",
       "  array([0.4672323], dtype=float32),\n",
       "  array([1.1383947], dtype=float32),\n",
       "  array([0.5118941], dtype=float32),\n",
       "  array([-0.44614312], dtype=float32),\n",
       "  array([0.3113143], dtype=float32),\n",
       "  array([-0.22066444], dtype=float32),\n",
       "  array([1.1308377], dtype=float32),\n",
       "  array([1.2466203], dtype=float32),\n",
       "  array([0.6775873], dtype=float32),\n",
       "  array([1.1870872], dtype=float32),\n",
       "  array([0.80624926], dtype=float32),\n",
       "  array([1.2103562], dtype=float32),\n",
       "  array([0.29084927], dtype=float32),\n",
       "  array([1.0349808], dtype=float32),\n",
       "  array([-0.14365911], dtype=float32),\n",
       "  array([-0.6861855], dtype=float32),\n",
       "  array([0.26313305], dtype=float32),\n",
       "  array([1.0678458], dtype=float32),\n",
       "  array([0.11130062], dtype=float32),\n",
       "  array([0.27899298], dtype=float32),\n",
       "  array([1.1208868], dtype=float32),\n",
       "  array([1.5323501], dtype=float32),\n",
       "  array([-0.3270149], dtype=float32),\n",
       "  array([0.43906742], dtype=float32),\n",
       "  array([0.0461303], dtype=float32),\n",
       "  array([0.4833185], dtype=float32),\n",
       "  array([-0.07430416], dtype=float32),\n",
       "  array([0.7452855], dtype=float32),\n",
       "  array([1.1604214], dtype=float32),\n",
       "  array([0.34796405], dtype=float32),\n",
       "  array([1.649589], dtype=float32),\n",
       "  array([0.67706424], dtype=float32),\n",
       "  array([0.49544042], dtype=float32),\n",
       "  array([0.28950018], dtype=float32),\n",
       "  array([0.82025397], dtype=float32),\n",
       "  array([0.507101], dtype=float32),\n",
       "  array([0.96375006], dtype=float32),\n",
       "  array([1.0024385], dtype=float32),\n",
       "  array([0.6732825], dtype=float32),\n",
       "  array([1.5631835], dtype=float32),\n",
       "  array([0.6000928], dtype=float32),\n",
       "  array([0.56350017], dtype=float32),\n",
       "  array([0.05126104], dtype=float32),\n",
       "  array([0.37280124], dtype=float32),\n",
       "  array([-0.14013307], dtype=float32),\n",
       "  array([-0.5226681], dtype=float32),\n",
       "  array([1.0031561], dtype=float32),\n",
       "  array([-0.146676], dtype=float32),\n",
       "  array([1.111386], dtype=float32),\n",
       "  array([-0.05492958], dtype=float32),\n",
       "  array([0.6698555], dtype=float32),\n",
       "  array([1.2813842], dtype=float32),\n",
       "  array([-0.42428952], dtype=float32)],\n",
       " 'rewards': [-2.413921748039275,\n",
       "  -2.46653155979567,\n",
       "  -2.630700508777535,\n",
       "  -2.931533320351852,\n",
       "  -3.3488159708812115,\n",
       "  -3.919057254014643,\n",
       "  -4.625798604092437,\n",
       "  -5.643888723709734,\n",
       "  -7.084237000140715,\n",
       "  -8.721614401094314,\n",
       "  -10.503953194752784,\n",
       "  -12.502558857954263,\n",
       "  -11.611055049948858,\n",
       "  -10.124889156865889,\n",
       "  -8.610618911120826,\n",
       "  -7.166636290046319,\n",
       "  -5.758632794614513,\n",
       "  -4.58817604051332,\n",
       "  -3.5770207959434597,\n",
       "  -2.7744870758152804,\n",
       "  -2.1105760429147815,\n",
       "  -1.6089056582616348,\n",
       "  -1.173991366340946,\n",
       "  -0.9136315660189661,\n",
       "  -0.6715282303440936,\n",
       "  -0.5111426937240554,\n",
       "  -0.3823982061302176,\n",
       "  -0.299141067416287,\n",
       "  -0.2507948226308602,\n",
       "  -0.22305650527350776,\n",
       "  -0.19834315999812693,\n",
       "  -0.17602028171255435,\n",
       "  -0.1559444818887974,\n",
       "  -0.1398615258373943,\n",
       "  -0.13275311044386937,\n",
       "  -0.12919471250760195,\n",
       "  -0.1236109864450058,\n",
       "  -0.11622154689152372,\n",
       "  -0.1120796464972406,\n",
       "  -0.1060213517448085,\n",
       "  -0.10839360040458283,\n",
       "  -0.12013078377346592,\n",
       "  -0.1226398215640918,\n",
       "  -0.12434701764579591,\n",
       "  -0.12586928697967026,\n",
       "  -0.1268638956338665,\n",
       "  -0.1262059446558192,\n",
       "  -0.12264381374812379,\n",
       "  -0.12174528557573853,\n",
       "  -0.11987920846798868,\n",
       "  -0.1225784607699299,\n",
       "  -0.12454739110539732,\n",
       "  -0.1298520072791654,\n",
       "  -0.13104102087405975,\n",
       "  -0.13036561035059363,\n",
       "  -0.1289619419287319,\n",
       "  -0.13479086996484665,\n",
       "  -0.1359206556534854,\n",
       "  -0.13494852481191363,\n",
       "  -0.1369207899009136,\n",
       "  -0.13649526513087687,\n",
       "  -0.13508978231961852,\n",
       "  -0.1326965271427853,\n",
       "  -0.12931894634998373,\n",
       "  -0.1225097815072644,\n",
       "  -0.11980282093750022,\n",
       "  -0.1167422051443475,\n",
       "  -0.11270382180801426,\n",
       "  -0.10539308901359566,\n",
       "  -0.09889577590599719,\n",
       "  -0.09222706992356106,\n",
       "  -0.08662582149425763,\n",
       "  -0.08027010965453502,\n",
       "  -0.07700684697432475,\n",
       "  -0.07249608820213363,\n",
       "  -0.06591598488418979,\n",
       "  -0.059970792039755166,\n",
       "  -0.05638222677575335,\n",
       "  -0.05819256651030183,\n",
       "  -0.05505729254013192,\n",
       "  -0.05462809294914002,\n",
       "  -0.05099982596165023,\n",
       "  -0.04377216695205572,\n",
       "  -0.040087740342727995,\n",
       "  -0.03694486209254042,\n",
       "  -0.031046221359688042,\n",
       "  -0.026735401309490113,\n",
       "  -0.01944681821539421,\n",
       "  -0.017230731481798496,\n",
       "  -0.016405033044988245,\n",
       "  -0.015309084186272996,\n",
       "  -0.014419802277852911,\n",
       "  -0.013606983955934694,\n",
       "  -0.010183513596651527,\n",
       "  -0.009022208438004347,\n",
       "  -0.008559015555200524,\n",
       "  -0.008409764168553682,\n",
       "  -0.01083713283826302,\n",
       "  -0.005656129851930364,\n",
       "  -0.007948821791585538,\n",
       "  -0.0048199528402916945,\n",
       "  -0.005007321253636444,\n",
       "  -0.009923585639659232,\n",
       "  -0.003146238588722887,\n",
       "  -0.004817730447279513,\n",
       "  -0.004013539742100419,\n",
       "  -0.007938055263985807,\n",
       "  -0.0080741346230705,\n",
       "  -0.003961534120414167,\n",
       "  -0.005992893195853613,\n",
       "  -0.008234829924090832,\n",
       "  -0.005662823295840346,\n",
       "  -0.006972489919214567,\n",
       "  -0.0060348270498991954,\n",
       "  -0.004883914352393537,\n",
       "  -0.00429542796174886,\n",
       "  -0.004652523563940845,\n",
       "  -0.003130117105065839,\n",
       "  -0.004325997140318782,\n",
       "  -0.008629872791314275,\n",
       "  -0.012092988276955223,\n",
       "  -0.0018981649398037228,\n",
       "  -0.0003212073339259919,\n",
       "  -0.0010716524836412336,\n",
       "  -0.0035197813919142936,\n",
       "  -0.004168622636902497,\n",
       "  -0.006909516432764443,\n",
       "  -0.0042001877793623,\n",
       "  -0.0031633918569893118,\n",
       "  -0.0052312607018090975,\n",
       "  -0.011507010427108581,\n",
       "  -0.014126054942934995,\n",
       "  -0.020763131881317565,\n",
       "  -0.011633305772418672,\n",
       "  -0.016120544770820436,\n",
       "  -0.03107850724503507,\n",
       "  -0.021965654814565694,\n",
       "  -0.020628823476221633,\n",
       "  -0.02016510856128934,\n",
       "  -0.018457515198996154,\n",
       "  -0.016232152617722553,\n",
       "  -0.019324697661017857,\n",
       "  -0.01577899652843699,\n",
       "  -0.016444442586859696,\n",
       "  -0.014991501319234705,\n",
       "  -0.01565240464760121,\n",
       "  -0.014196532191684649,\n",
       "  -0.013366959688093406,\n",
       "  -0.014241285392710485,\n",
       "  -0.01306240357917836,\n",
       "  -0.011916026540427352,\n",
       "  -0.011750562819220208,\n",
       "  -0.01307625788400155,\n",
       "  -0.019952001524738857,\n",
       "  -0.019185596381489138,\n",
       "  -0.017078321598513916,\n",
       "  -0.01831299571569603,\n",
       "  -0.01708835133577957,\n",
       "  -0.01723303986226029,\n",
       "  -0.01609671833039049,\n",
       "  -0.01436889173973453,\n",
       "  -0.013719709142004557,\n",
       "  -0.01013911626425037,\n",
       "  -0.009458947855576584,\n",
       "  -0.011919393895133374,\n",
       "  -0.010007412279825361,\n",
       "  -0.011157722369792365,\n",
       "  -0.01398960997335459,\n",
       "  -0.014233179492390528,\n",
       "  -0.012365544055446532,\n",
       "  -0.010552887921367179,\n",
       "  -0.010366332496576206,\n",
       "  -0.011824967358302846,\n",
       "  -0.012514834481569186,\n",
       "  -0.017279462713708987,\n",
       "  -0.01909145671395518,\n",
       "  -0.01699036349006273,\n",
       "  -0.021781637421615672,\n",
       "  -0.017966718948398238,\n",
       "  -0.017236559844106582,\n",
       "  -0.016696466808807094,\n",
       "  -0.017809478695580132,\n",
       "  -0.01739810265767939,\n",
       "  -0.0185568038915317,\n",
       "  -0.018363893226382804,\n",
       "  -0.017367617483194108,\n",
       "  -0.018517133740960597,\n",
       "  -0.017913798144852628,\n",
       "  -0.015705986165832093,\n",
       "  -0.013517948071721402,\n",
       "  -0.009835997420431236,\n",
       "  -0.008244577117187594,\n",
       "  -0.00607234871882816,\n",
       "  -0.006847889457666604,\n",
       "  -0.005448681761791863,\n",
       "  -0.006865854762298397,\n",
       "  -0.005543189354068948,\n",
       "  -0.005322800476906297,\n",
       "  -0.006464213200929356,\n",
       "  -0.007577828960186859],\n",
       " 'terminated': [False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " 'truncated': [False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True]}"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_trajectory(env, actor, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, tensor([-1.1921e-07], grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.predict(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(\n",
    "    [\n",
    "        actor.predict(env.observation_space.sample())[1],\n",
    "        actor.predict(env.observation_space.sample())[1],\n",
    "    ], dim=0\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlib.common.buffer import RolloutBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = RolloutBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.collect_rollouts(env, actor, rollout_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rb.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"observations\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"actions\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.forward(data[\"observations\"])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = data[\"observations\"]\n",
    "actions = data[\"actions\"]\n",
    "old_log_probs = data[\"log_probs\"]\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3740],\n",
      "        [-1.1309],\n",
      "        [-0.8666],\n",
      "        [-0.5748],\n",
      "        [-0.2473],\n",
      "        [ 0.1240],\n",
      "        [ 0.5114],\n",
      "        [ 0.8700],\n",
      "        [ 1.1968],\n",
      "        [ 1.4914]], grad_fn=<DivBackward0>)\n",
      "torch.Size([10, 1])\n",
      "torch.Size([]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "loss = {}\n",
    "\n",
    "_, new_log_probs = actor.get_action(observations, action=actions)\n",
    "\n",
    "ratio = torch.exp(new_log_probs - old_log_probs.detach())\n",
    "ratio_clipped = torch.clamp(ratio, 1 - epsilon, 1 + epsilon)\n",
    "\n",
    "values = critic(observations).reshape(ratio.shape)\n",
    "\n",
    "targets = data[\"q_estimations\"].reshape(ratio.shape)\n",
    "advantages = targets.detach() - values\n",
    "# print(targets.shape, values.shape, advantages.shape)\n",
    "# print(old_log_probs.shape, new_log_probs.shape, ratio.shape)\n",
    "\n",
    "if True:\n",
    "    mean = advantages.mean()\n",
    "    std = advantages.std()\n",
    "    advantages = (advantages - mean) / (std + 1e-8)\n",
    "\n",
    "actor_loss_1 = ratio * advantages.detach()\n",
    "actor_loss_2 = ratio_clipped * advantages.detach()\n",
    "\n",
    "print(advantages)\n",
    "print(advantages.shape)\n",
    "\n",
    "loss[\"actor\"] = -(torch.min(actor_loss_1, actor_loss_2)).mean()\n",
    "loss[\"critic\"] = (advantages**2).mean()\n",
    "\n",
    "print(loss[\"actor\"].shape, loss[\"critic\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-945.4736045591187"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(env, actor, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = torch.zeros((1, 2))\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = torch.ones((1, 2))\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Normal(mu, std)\n",
    "action = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(action).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9676])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(action).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\")\n",
    "agent = PPO(\"MlpPolicy\", env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03049863, -0.9995348 ,  0.8736682 ], dtype=float32), {})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _ = agent.predict(\n",
    "    env.observation_space.sample(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9694774], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.02193137, -0.9997595 , -0.17140453], dtype=float32),\n",
       " -2.4527108869676995,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
