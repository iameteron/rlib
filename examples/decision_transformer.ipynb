{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from rlib.algorithms.sac import sac\n",
    "from rlib.common.buffer import ReplayBuffer, RolloutBuffer\n",
    "from rlib.common.evaluation import get_trajectory, save_frames_as_gif, validation\n",
    "from rlib.common.logger import TensorBoardLogger\n",
    "from rlib.common.policies import DeterministicMlpPolicy, MlpQCritic, StochasticMlpPolicy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "min_action, max_action = -1, 1\n",
    "env = RescaleAction(env, min_action, max_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    }
   ],
   "source": [
    "obs_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "trajectory_len = 200\n",
    "\n",
    "print(obs_dim, action_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/pendulum_stoc_expert\", \"rb\") as file:\n",
    "    expert_actor = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = RolloutBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-131.84307331613581"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(env, expert_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.collect_rollouts(env, expert_actor, trajectories_n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rb.get_data()\n",
    "expert_trajectories = rb.get_trajectories(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expert_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/expert_trajectories\", \"wb\") as file:\n",
    "    pickle.dump(expert_trajectories, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/expert_trajectories\", \"rb\") as file:\n",
    "    expert_trajectories = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expert_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim: int,\n",
    "        action_dim: int,\n",
    "        trajectory_len: int,\n",
    "        embedding_dim: int = 32,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.R_embedding = nn.Linear(1, embedding_dim)\n",
    "        self.s_embedding = nn.Linear(obs_dim, embedding_dim)\n",
    "        self.a_embedding = nn.Linear(action_dim, embedding_dim)\n",
    "\n",
    "        self.t_embedding = nn.Embedding(trajectory_len, embedding_dim)\n",
    "\n",
    "        decoder_layer = nn.TransformerEncoderLayer(\n",
    "            embedding_dim,\n",
    "            nhead,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(decoder_layer, num_layers)\n",
    "        self.head = nn.Linear(embedding_dim, action_dim)\n",
    "\n",
    "    def forward(self, R, s, a, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            R (torch.Tensor): (B, T, 1)\n",
    "            s (torch.Tensor): (B, T, obs_dim)\n",
    "            a (torch.Tensor): (B, T, action_dim)\n",
    "            t (torch.Tensor): (B, T, 1)\n",
    "\n",
    "        Returns:\n",
    "            a_pred: (torch.Tensor): (B, T, action_dim)\n",
    "        \"\"\"\n",
    "        t_emb = self.t_embedding(t.squeeze()).squeeze()\n",
    "\n",
    "        R_emb = self.R_embedding(R) + t_emb  # (B, T, C)\n",
    "        s_emb = self.s_embedding(s) + t_emb  # (B, T, C)\n",
    "        a_emb = self.a_embedding(a) + t_emb  # (B, T, C)\n",
    "\n",
    "        B, T, C = R_emb.shape\n",
    "\n",
    "        token_emb = torch.stack((R_emb, s_emb, a_emb), dim=2) # (B, 3, T, C)\n",
    "        token_emb = token_emb.view(B, 3 * T, C) # (B, 3T, C)\n",
    "\n",
    "        mask = nn.Transformer.generate_square_subsequent_mask(3 * T)\n",
    "\n",
    "        hidden_states = self.transformer.forward(token_emb, mask)  # (B, 3T, C)\n",
    "        a_hidden = hidden_states[:, 2::3, :]  # (B, T, C)\n",
    "        a_pred = torch.tanh(self.head(a_hidden))  # (B, T, action_dim)\n",
    "\n",
    "        return a_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, trajectories, K):\n",
    "        self.trajectories = trajectories\n",
    "        self._add_timesteps()\n",
    "\n",
    "        self.sequences = []\n",
    "\n",
    "        for traj in self.trajectories:\n",
    "            traj_len = traj[\"observations\"].shape[0]\n",
    "            for i in range(0, traj_len - K + 1):\n",
    "                R = traj[\"q_estimations\"][i: i + K]\n",
    "                s = traj[\"observations\"][i: i + K]\n",
    "                a = traj[\"actions\"][i: i + K]\n",
    "                t = traj[\"timesteps\"][i: i + K]\n",
    "\n",
    "                self.sequences.append((R, s, a, t))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sequences[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def _add_timesteps(self):\n",
    "        for traj in self.trajectories:\n",
    "            traj_len = traj[\"observations\"].shape[0]\n",
    "            traj[\"timesteps\"] = torch.arange(0, traj_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: DecisionTransformer, env: gym.Env, target_return, K):\n",
    "\n",
    "    model.eval()\n",
    "    obs, _ = env.reset()\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    R = torch.tensor(target_return, dtype=torch.float32).reshape(1, 1, 1)\n",
    "    s = torch.tensor(obs, dtype=torch.float32).reshape(1, 1, -1)\n",
    "    a = torch.tensor(action, dtype=torch.float32).reshape(1, 1, -1)\n",
    "    t = torch.tensor(0).reshape(1, 1, 1)\n",
    "\n",
    "    rewards = []\n",
    "\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            a_pred = model.forward(R, s, a, t)[:, -1, :]\n",
    "        a_pred = a_pred.reshape(1, 1, -1)\n",
    "\n",
    "        action = a_pred.detach().numpy()\n",
    "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "        next_obs = torch.tensor(next_obs, dtype=torch.float32).reshape(1, 1, -1)\n",
    "        reward = torch.tensor(reward, dtype=torch.float32).reshape(1, 1, 1)\n",
    "\n",
    "        return_to_go = R[:, -1, :] - reward\n",
    "        timestep = t[:, -1, :] + 1\n",
    "        timestep = timestep.reshape(1, 1, 1)\n",
    "\n",
    "        R = torch.cat((R, return_to_go), dim=1)[:, -K:, :]\n",
    "        s = torch.cat((s, next_obs), dim=1)[:, -K:, :]\n",
    "        a = torch.cat((a, a_pred), dim=1)[:, -K:, :]\n",
    "        t = torch.cat((t, timestep), dim=1)[:, -K:, :]\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    return sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    decision_transformer: DecisionTransformer,\n",
    "    optimizer: Adam,\n",
    "    train_dataloader: DataLoader,\n",
    "    test_dataloader: DataLoader,\n",
    "    total_epochs: int = 100,\n",
    "    max_return: float = -200,\n",
    "):\n",
    "    logger = TensorBoardLogger(log_dir=\"./tb_logs/dt_\")\n",
    "\n",
    "    for epoch_n in range(total_epochs):\n",
    "        train_losses, test_losses = [], []\n",
    "\n",
    "        decision_transformer.train()\n",
    "        for R, s, a, t in train_dataloader:\n",
    "            a_preds = decision_transformer(R, s, a, t)\n",
    "\n",
    "            batch_loss = ((a_preds - a) ** 2).mean()\n",
    "            train_losses.append(batch_loss.item())\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        decision_transformer.eval()\n",
    "        with torch.no_grad():\n",
    "            for R, s, a, t in test_dataloader:\n",
    "                a_preds = decision_transformer(R, s, a, t)\n",
    "                batch_loss = ((a_preds - a) ** 2).mean()\n",
    "                test_losses.append(batch_loss.item())\n",
    "\n",
    "        loss = {}\n",
    "        loss[\"train\"] = sum(train_losses) / len(train_losses)\n",
    "        loss[\"test\"] = sum(test_losses) / len(test_losses)\n",
    "        logger.log_scalars(loss, epoch_n)\n",
    "\n",
    "        metrics = {}\n",
    "        metrics[\"traj_reward\"] = evaluation(decision_transformer, env, max_return, K=5)\n",
    "        logger.log_scalars(metrics, epoch_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97500\n"
     ]
    }
   ],
   "source": [
    "dataset = TrajectoryDataset(expert_trajectories, K=5)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, (train_size, test_size))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_transformer = DecisionTransformer(obs_dim, action_dim, trajectory_len)\n",
    "optimizer = Adam(decision_transformer.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    decision_transformer,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    total_epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(decision_transformer, env, -150, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 2, 4, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1 * torch.ones((B, T, C))\n",
    "s = 2 * torch.ones((B, T, C))\n",
    "a = 3 * torch.ones((B, T, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.]]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.cat((R, s, a), dim=1)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3, 3]),\n",
       " tensor([[[[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]],\n",
       " \n",
       "          [[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]],\n",
       " \n",
       "          [[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]],\n",
       " \n",
       "          [[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]]],\n",
       " \n",
       " \n",
       "         [[[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]],\n",
       " \n",
       "          [[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]],\n",
       " \n",
       "          [[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]],\n",
       " \n",
       "          [[1., 1., 1.],\n",
       "           [2., 2., 2.],\n",
       "           [3., 3., 3.]]]]))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.stack((R, s, a), dim=2)\n",
    "tokens.shape, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-51.6459],\n",
       "          [-54.7376],\n",
       "          [-58.0769],\n",
       "          [-61.2564],\n",
       "          [-63.7972]]]),\n",
       " tensor([[[ 0.0372, -0.9993,  0.5102],\n",
       "          [ 0.0102, -0.9999, -0.5390],\n",
       "          [-0.0692, -0.9976, -1.5889],\n",
       "          [-0.1997, -0.9799, -2.6371],\n",
       "          [-0.3753, -0.9269, -3.6720]]]),\n",
       " tensor([[[-0.9991],\n",
       "          [-0.9997],\n",
       "          [-1.0002],\n",
       "          [-1.0001],\n",
       "          [-0.9999]]]),\n",
       " tensor([[0, 1, 2, 3, 4]])]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 10\n",
    "embedding_dim = 32\n",
    "\n",
    "emb_table = nn.Embedding(num_embeddings, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "\n",
    "decoder_layer = nn.TransformerDecoderLayer(\n",
    "    d_model=embedding_dim,\n",
    "    nhead=4,\n",
    "    batch_first=True,\n",
    ")\n",
    "\n",
    "transformer = nn.TransformerDecoder(decoder_layer, num_layers=3)\n",
    "\n",
    "B = 4\n",
    "T = 10\n",
    "C = embedding_dim\n",
    "\n",
    "tgt = torch.zeros((B, T, C))\n",
    "tgt_mask = nn.Transformer.generate_square_subsequent_mask(T)\n",
    "\n",
    "memory = torch.zeros((B, 1, C))\n",
    "\n",
    "transformer.forward(\n",
    "    tgt=tgt,\n",
    "    memory=memory,\n",
    "    tgt_mask=tgt_mask,\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
