{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from rlib.algorithms.sac import sac\n",
    "from rlib.common.buffer import ReplayBuffer, RolloutBuffer\n",
    "from rlib.common.evaluation import get_trajectory, save_frames_as_gif, validation\n",
    "from rlib.common.logger import TensorBoardLogger\n",
    "from rlib.common.policies import DeterministicMlpPolicy, MlpQCritic, StochasticMlpPolicy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "min_action, max_action = -1, 1\n",
    "env = RescaleAction(env, min_action, max_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    }
   ],
   "source": [
    "obs_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "trajectory_len = 200\n",
    "\n",
    "print(obs_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/pendulum_stoc_expert\", \"rb\") as file:\n",
    "    expert_actor = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = RolloutBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.collect_rollouts(env, expert_actor, trajectories_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rb.get_data()\n",
    "expert_trajectories = rb.get_trajectories(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3213e+00],\n",
       "        [-9.3062e+00],\n",
       "        [-9.2314e+00],\n",
       "        [-9.1002e+00],\n",
       "        [-8.9172e+00],\n",
       "        [-8.6883e+00],\n",
       "        [-8.4207e+00],\n",
       "        [-8.1240e+00],\n",
       "        [-7.8083e+00],\n",
       "        [-7.4833e+00],\n",
       "        [-7.1585e+00],\n",
       "        [-6.8543e+00],\n",
       "        [-6.6680e+00],\n",
       "        [-6.7582e+00],\n",
       "        [-7.1258e+00],\n",
       "        [-7.7598e+00],\n",
       "        [-8.6369e+00],\n",
       "        [-9.7198e+00],\n",
       "        [-1.0865e+01],\n",
       "        [-9.9924e+00],\n",
       "        [-9.0551e+00],\n",
       "        [-8.0828e+00],\n",
       "        [-7.1102e+00],\n",
       "        [-6.1688e+00],\n",
       "        [-5.2086e+00],\n",
       "        [-4.3655e+00],\n",
       "        [-3.9019e+00],\n",
       "        [-3.8279e+00],\n",
       "        [-4.1469e+00],\n",
       "        [-4.8658e+00],\n",
       "        [-5.9872e+00],\n",
       "        [-7.4943e+00],\n",
       "        [-9.3196e+00],\n",
       "        [-1.1418e+01],\n",
       "        [-1.2574e+01],\n",
       "        [-1.1125e+01],\n",
       "        [-9.5973e+00],\n",
       "        [-8.0586e+00],\n",
       "        [-6.5907e+00],\n",
       "        [-5.2656e+00],\n",
       "        [-4.1284e+00],\n",
       "        [-3.1889e+00],\n",
       "        [-2.4376e+00],\n",
       "        [-1.8541e+00],\n",
       "        [-1.3279e+00],\n",
       "        [-9.8674e-01],\n",
       "        [-6.9770e-01],\n",
       "        [-5.3355e-01],\n",
       "        [-3.5917e-01],\n",
       "        [-2.6528e-01],\n",
       "        [-1.6683e-01],\n",
       "        [-1.0288e-01],\n",
       "        [-4.9750e-02],\n",
       "        [-1.8886e-02],\n",
       "        [-7.6614e-03],\n",
       "        [-4.1721e-03],\n",
       "        [-4.4410e-03],\n",
       "        [-4.9061e-03],\n",
       "        [-5.1770e-03],\n",
       "        [-5.4465e-03],\n",
       "        [-5.7099e-03],\n",
       "        [-5.8967e-03],\n",
       "        [-6.1082e-03],\n",
       "        [-6.3046e-03],\n",
       "        [-6.4783e-03],\n",
       "        [-6.6121e-03],\n",
       "        [-6.7851e-03],\n",
       "        [-6.9420e-03],\n",
       "        [-7.0280e-03],\n",
       "        [-7.1556e-03],\n",
       "        [-7.2088e-03],\n",
       "        [-7.2964e-03],\n",
       "        [-7.3816e-03],\n",
       "        [-7.4508e-03],\n",
       "        [-7.5164e-03],\n",
       "        [-7.5573e-03],\n",
       "        [-7.5519e-03],\n",
       "        [-7.6259e-03],\n",
       "        [-7.6364e-03],\n",
       "        [-7.6817e-03],\n",
       "        [-7.7354e-03],\n",
       "        [-7.7315e-03],\n",
       "        [-7.7638e-03],\n",
       "        [-7.7900e-03],\n",
       "        [-7.8044e-03],\n",
       "        [-7.8128e-03],\n",
       "        [-7.8532e-03],\n",
       "        [-7.8528e-03],\n",
       "        [-7.9027e-03],\n",
       "        [-7.8892e-03],\n",
       "        [-7.8621e-03],\n",
       "        [-7.9091e-03],\n",
       "        [-7.8669e-03],\n",
       "        [-7.8540e-03],\n",
       "        [-7.8767e-03],\n",
       "        [-7.8679e-03],\n",
       "        [-7.9332e-03],\n",
       "        [-7.9499e-03],\n",
       "        [-7.9352e-03],\n",
       "        [-7.9309e-03],\n",
       "        [-7.9662e-03],\n",
       "        [-7.9417e-03],\n",
       "        [-7.9526e-03],\n",
       "        [-7.9691e-03],\n",
       "        [-7.9282e-03],\n",
       "        [-7.9792e-03],\n",
       "        [-7.9108e-03],\n",
       "        [-7.9622e-03],\n",
       "        [-7.9464e-03],\n",
       "        [-7.9732e-03],\n",
       "        [-7.9498e-03],\n",
       "        [-7.9657e-03],\n",
       "        [-7.9922e-03],\n",
       "        [-8.0033e-03],\n",
       "        [-7.9951e-03],\n",
       "        [-7.9712e-03],\n",
       "        [-7.9805e-03],\n",
       "        [-7.9735e-03],\n",
       "        [-7.9748e-03],\n",
       "        [-7.9685e-03],\n",
       "        [-7.9757e-03],\n",
       "        [-7.9935e-03],\n",
       "        [-7.9579e-03],\n",
       "        [-7.9767e-03],\n",
       "        [-7.9562e-03],\n",
       "        [-7.9929e-03],\n",
       "        [-7.9645e-03],\n",
       "        [-7.9805e-03],\n",
       "        [-7.9662e-03],\n",
       "        [-7.9820e-03],\n",
       "        [-8.0087e-03],\n",
       "        [-7.9906e-03],\n",
       "        [-7.9769e-03],\n",
       "        [-8.0202e-03],\n",
       "        [-7.9823e-03],\n",
       "        [-7.9920e-03],\n",
       "        [-8.0148e-03],\n",
       "        [-8.0064e-03],\n",
       "        [-7.9580e-03],\n",
       "        [-8.0183e-03],\n",
       "        [-7.9775e-03],\n",
       "        [-8.0080e-03],\n",
       "        [-8.0162e-03],\n",
       "        [-7.9905e-03],\n",
       "        [-8.0044e-03],\n",
       "        [-8.0075e-03],\n",
       "        [-8.0362e-03],\n",
       "        [-7.9818e-03],\n",
       "        [-8.0113e-03],\n",
       "        [-7.9896e-03],\n",
       "        [-8.0104e-03],\n",
       "        [-7.9716e-03],\n",
       "        [-7.9584e-03],\n",
       "        [-7.9519e-03],\n",
       "        [-8.0125e-03],\n",
       "        [-7.9885e-03],\n",
       "        [-7.9888e-03],\n",
       "        [-7.9836e-03],\n",
       "        [-8.0364e-03],\n",
       "        [-7.9849e-03],\n",
       "        [-7.9868e-03],\n",
       "        [-8.0133e-03],\n",
       "        [-7.9732e-03],\n",
       "        [-7.9946e-03],\n",
       "        [-7.9859e-03],\n",
       "        [-7.9765e-03],\n",
       "        [-7.9788e-03],\n",
       "        [-7.9522e-03],\n",
       "        [-7.9326e-03],\n",
       "        [-7.9770e-03],\n",
       "        [-7.8998e-03],\n",
       "        [-7.9151e-03],\n",
       "        [-7.9179e-03],\n",
       "        [-7.9370e-03],\n",
       "        [-7.9562e-03],\n",
       "        [-7.9258e-03],\n",
       "        [-7.9387e-03],\n",
       "        [-7.9581e-03],\n",
       "        [-7.9262e-03],\n",
       "        [-7.9034e-03],\n",
       "        [-7.9663e-03],\n",
       "        [-7.9143e-03],\n",
       "        [-7.9384e-03],\n",
       "        [-7.8870e-03],\n",
       "        [-7.9453e-03],\n",
       "        [-7.9126e-03],\n",
       "        [-7.9203e-03],\n",
       "        [-7.8993e-03],\n",
       "        [-7.9161e-03],\n",
       "        [-7.9465e-03],\n",
       "        [-7.9355e-03],\n",
       "        [-7.9191e-03],\n",
       "        [-7.9384e-03],\n",
       "        [-7.9250e-03],\n",
       "        [-7.9010e-03],\n",
       "        [-7.9197e-03],\n",
       "        [-7.9480e-03],\n",
       "        [-7.9494e-03],\n",
       "        [-7.9209e-03],\n",
       "        [-7.9019e-03]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_trajectories[0][\"rewards\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_trajectories[49][\"q_estimations\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim: int,\n",
    "        action_dim: int,\n",
    "        trajectory_len: int,\n",
    "        embedding_dim: int = 32,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.R_embedding = nn.Linear(1, embedding_dim)\n",
    "        self.s_embedding = nn.Linear(obs_dim, embedding_dim)\n",
    "        self.a_embedding = nn.Linear(action_dim, embedding_dim)\n",
    "\n",
    "        self.t_embedding = nn.Embedding(trajectory_len, embedding_dim)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            embedding_dim,\n",
    "            nhead,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.head = nn.Linear(embedding_dim, action_dim)\n",
    "\n",
    "    def forward(self, R, s, a, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            R (torch.Tensor): (B, T, 1)\n",
    "            s (torch.Tensor): (B, T, obs_dim)\n",
    "            a (torch.Tensor): (B, T, action_dim)\n",
    "            t (torch.Tensor): (B, T, 1)\n",
    "\n",
    "        Returns:\n",
    "            a_pred: (torch.Tensor): (B, T, action_dim)\n",
    "        \"\"\"\n",
    "        t_emb = self.t_embedding(t).squeeze()\n",
    "\n",
    "        R_emb = self.R_embedding(R) + t_emb  # (B, T, C)\n",
    "        s_emb = self.s_embedding(s) + t_emb  # (B, T, C)\n",
    "        a_emb = self.a_embedding(a) + t_emb  # (B, T, C)\n",
    "\n",
    "        B, T, C = R_emb.shape\n",
    "\n",
    "        token_emb = torch.cat((R_emb, s_emb, a_emb), dim=1)  # (B, 3T, C)\n",
    "\n",
    "        memory = torch.zeros_like(token_emb)\n",
    "        mask = nn.Transformer.generate_square_subsequent_mask(3 * T)\n",
    "\n",
    "        hidden_states = self.transformer.forward(token_emb, memory, mask)  # (B, 3T, C)\n",
    "        a_hidden = hidden_states[:, 2::3, :]  # (B, T, C)\n",
    "        a_pred = self.head(a_hidden)  # (B, T, 1)\n",
    "\n",
    "        return a_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTransformer(obs_dim, action_dim, trajectory_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, trajectories, K):\n",
    "        self.sequences\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (\n",
    "            self.trajectories[\"q_estimations\"][i],\n",
    "            self.trajectories[\"observations\"][i],\n",
    "            self.trajectories[\"actions\"][i],\n",
    "            self.trajectories[\"timesteps\"][i],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.trajectories[\"observations\"].shape[0]\n",
    "\n",
    "    def _add_timesteps(self):\n",
    "        rollout_size = self.trajectories[\"observations\"].shape[0]\n",
    "        self.trajectories[\"timesteps\"] = torch.zeros(\n",
    "            (rollout_size, 1), dtype=torch.int64\n",
    "        )\n",
    "\n",
    "        count = 0\n",
    "        for i in range(rollout_size):\n",
    "            self.trajectories[\"timesteps\"][i] = count\n",
    "            count += 1\n",
    "\n",
    "            if self.trajectories[\"terminated\"][i] or self.trajectories[\"truncated\"][i]:\n",
    "                count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    decision_transformer: DecisionTransformer,\n",
    "    optimizer: Adam,\n",
    "    train_dataloader: DataLoader,\n",
    "    test_dataloader: DataLoader,\n",
    "    total_epochs: int = 10,\n",
    "):\n",
    "    logger = TensorBoardLogger(log_dir=\"./tb_logs/dt_\")\n",
    "\n",
    "    for epoch_n in range(total_epochs):\n",
    "        loss = {\"train\": 0, \"test\": 0}\n",
    "\n",
    "        for R, s, a, t in train_dataloader:\n",
    "            print(\n",
    "                R.shape,\n",
    "                s.shape,\n",
    "            )\n",
    "            a_preds = decision_transformer(R, s, a, t)\n",
    "            batch_loss = ((a_preds - a) ** 2).mean()\n",
    "            loss[\"train\"] += batch_loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for R, s, a, t in test_dataloader:\n",
    "                a_preds = decision_transformer(R, s, a, t)\n",
    "                batch_loss = ((a_preds - a) ** 2).mean()\n",
    "                loss[\"test\"] += batch_loss.item()\n",
    "\n",
    "        logger.log_scalars(loss, epoch_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrajectoryDataset(expert_trajectories)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, (train_size, test_size))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_transformer = DecisionTransformer(obs_dim, action_dim, trajectory_len)\n",
    "optimizer = Adam(decision_transformer.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1]) torch.Size([128, 3])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecision_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[45], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(decision_transformer, optimizer, train_dataloader, test_dataloader, total_epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m R, s, a, t \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     15\u001b[0m         R\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m     16\u001b[0m         s\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m     17\u001b[0m     )\n\u001b[1;32m---> 18\u001b[0m     a_preds \u001b[38;5;241m=\u001b[39m \u001b[43mdecision_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m ((a_preds \u001b[38;5;241m-\u001b[39m a) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     20\u001b[0m     loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[38], line 44\u001b[0m, in \u001b[0;36mDecisionTransformer.forward\u001b[1;34m(self, R, s, a, t)\u001b[0m\n\u001b[0;32m     41\u001b[0m s_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_embedding(s) \u001b[38;5;241m+\u001b[39m t_emb \u001b[38;5;66;03m# (B, T, C)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m a_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_embedding(a) \u001b[38;5;241m+\u001b[39m t_emb \u001b[38;5;66;03m# (B, T, C)\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m B, T, C \u001b[38;5;241m=\u001b[39m R_emb\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     46\u001b[0m token_emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((R_emb, s_emb, a_emb), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, 3T, C)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(token_emb)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    decision_transformer,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1]) torch.Size([128, 3]) torch.Size([128, 1]) torch.Size([128, 1])\n",
      "torch.float32 torch.float32 torch.float32 torch.int64\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 32, but got 96",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 18\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      5\u001b[0m     R\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m      6\u001b[0m     s\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m      7\u001b[0m     a\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m      8\u001b[0m     t\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     12\u001b[0m     R\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m     13\u001b[0m     s\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m     14\u001b[0m     a\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m     15\u001b[0m     t\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m a_preds \u001b[38;5;241m=\u001b[39m \u001b[43mdecision_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m ((a_preds \u001b[38;5;241m-\u001b[39m a) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     20\u001b[0m loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[151], line 50\u001b[0m, in \u001b[0;36mDecisionTransformer.forward\u001b[1;34m(self, R, s, a, t)\u001b[0m\n\u001b[0;32m     47\u001b[0m memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(token_emb)\n\u001b[0;32m     48\u001b[0m mask \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer\u001b[38;5;241m.\u001b[39mgenerate_square_subsequent_mask(T)\n\u001b[1;32m---> 50\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m a_hidden \u001b[38;5;241m=\u001b[39m hidden_states[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     52\u001b[0m a_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(a_hidden)\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:602\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    599\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 602\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:1087\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x))\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1086\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m-> 1087\u001b[0m         x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1088\u001b[0m     )\n\u001b[0;32m   1089\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\n\u001b[0;32m   1090\u001b[0m         x\n\u001b[0;32m   1091\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(\n\u001b[0;32m   1092\u001b[0m             x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m     )\n\u001b[0;32m   1095\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:1107\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1102\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1343\u001b[0m         query,\n\u001b[0;32m   1344\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\nsorokin\\code\\envs\\rl-env\\lib\\site-packages\\torch\\nn\\functional.py:6069\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   6063\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6064\u001b[0m         \u001b[38;5;66;03m# We have the attn_mask, and use that to merge kpm into it.\u001b[39;00m\n\u001b[0;32m   6065\u001b[0m         \u001b[38;5;66;03m# Turn off use of is_causal hint, as the merged mask is no\u001b[39;00m\n\u001b[0;32m   6066\u001b[0m         \u001b[38;5;66;03m# longer causal.\u001b[39;00m\n\u001b[0;32m   6067\u001b[0m         is_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 6069\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m   6070\u001b[0m     embed_dim \u001b[38;5;241m==\u001b[39m embed_dim_to_check\n\u001b[0;32m   6071\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas expecting embedding dimension of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embed_dim, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   6073\u001b[0m     \u001b[38;5;66;03m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[0;32m   6074\u001b[0m     head_dim \u001b[38;5;241m=\u001b[39m embed_dim\u001b[38;5;241m.\u001b[39mdiv(num_heads, rounding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrunc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: was expecting embedding dimension of 32, but got 96"
     ]
    }
   ],
   "source": [
    "loss = {\"train\": 0, \"test\": 0}\n",
    "\n",
    "for R, s, a, t in train_dataloader:\n",
    "    print(R.shape, s.shape, a.shape, t.shape)\n",
    "\n",
    "    print(R.dtype, s.dtype, a.dtype, t.dtype)\n",
    "\n",
    "    a_preds = decision_transformer(R, s, a, t)\n",
    "    batch_loss = ((a_preds - a) ** 2).mean()\n",
    "    loss[\"train\"] += batch_loss.item()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 10\n",
    "embedding_dim = 32\n",
    "\n",
    "emb_table = nn.Embedding(num_embeddings, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "\n",
    "decoder_layer = nn.TransformerDecoderLayer(\n",
    "    d_model=embedding_dim,\n",
    "    nhead=4,\n",
    "    batch_first=True,\n",
    ")\n",
    "\n",
    "transformer = nn.TransformerDecoder(decoder_layer, num_layers=3)\n",
    "\n",
    "B = 4\n",
    "T = 10\n",
    "C = embedding_dim\n",
    "\n",
    "tgt = torch.zeros((B, T, C))\n",
    "tgt_mask = nn.Transformer.generate_square_subsequent_mask(T)\n",
    "\n",
    "memory = torch.zeros((B, 1, C))\n",
    "\n",
    "transformer.forward(\n",
    "    tgt=tgt,\n",
    "    memory=memory,\n",
    "    tgt_mask=tgt_mask,\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
